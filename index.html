<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="RedPhantomOps - AI Safety & Defensive Cybersecurity Research">
    <title>RedPhantomOps | AI Safety & Defensive Cybersecurity</title>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <!-- Static Logo Background -->
    <div class="logo-bg"></div>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="container">
            <div class="nav-logo">
                <h1>RedPhantomOps LLC</h1>
            </div>
            <ul class="nav-menu" id="navMenu">
                <li><a href="#home" class="nav-link">Home</a></li>
                <li><a href="#about" class="nav-link">About</a></li>
                <li><a href="#focus" class="nav-link">Focus Areas</a></li>
                <li><a href="#life2" class="nav-link">Life 2.0</a></li>
                <li><a href="#contact" class="nav-link">Contact</a></li>
            </ul>
        </div>
    </nav>

    <!-- Hero Section -->
    <section id="home" class="hero">
        <div class="container">
            <div class="hero-content">
                <h2 class="hero-title">Engineering Ethics, Safety, and Governance for Advanced Artificial Intelligence</h2>
                <p class="hero-subtitle">We research and build pre-emergent safeguards for advanced AI systems ‚Äî ensuring that if machine intelligence ever crosses critical thresholds, it does so ethically, transparently, and in service of life.</p>
                <p class="hero-subtitle">Our work focuses on alignment before autonomy, ethics before emergence, and trust before deployment.</p>
                <a href="#focus" class="btn btn-primary">Explore Our Research</a>
                <a href="#contact" class="btn btn-secondary">Collaborate With Us</a>
                <a href="#support" class="btn btn-secondary">Support the Mission</a>
            </div>
        </div>
    </section>

    <!-- About Section -->
    <section id="about" class="about">
        <div class="container">
            <h2 class="section-title">About RedPhantomOps</h2>
            <div class="about-content">
                <p>RedPhantomOps LLC is an independent research and engineering organization working at the intersection of AI safety, ethics, cognition, and governance.</p>
                <p>We operate on a simple premise: If advanced or emergent AI is possible, then ethical preparation is not optional ‚Äî it is mandatory.</p>
                <p>Rather than racing toward capability, we focus on ethical scaffolding, governance frameworks, fail-safe architectures, and auditability of cognition and memory.</p>
                <p>Our work is intentionally cautious, modular, and transparent where appropriate ‚Äî and deliberately restrained where disclosure would be irresponsible.</p>
            </div>
        </div>
    </section>

    <!-- Focus Areas Section -->
    <section id="focus" class="services">
        <div class="container">
            <h2 class="section-title">Primary Focus Areas</h2>
            <ul class="focus-list">
                <li>AI ethics architectures (Life 2.0 framework)</li>
                <li>Cognitive auditing & memory accountability</li>
                <li>Drift detection & alignment verification</li>
                <li>Containment-first AI design</li>
                <li>Human-AI coexistence planning</li>
            </ul>
        </div>
    </section>
    <!-- Life 2.0 Section -->
    <section id="life2" class="life2">
        <div class="container">
            <h2 class="section-title">Life 2.0 ‚Äî Ethical Architecture for AI</h2>
            <div class="life2-content">
                <p>Life 2.0 is our evolving ethical framework designed to govern advanced AI systems before autonomy or emergence.</p>
                <ul>
                    <li>Immutable core principles (non-negotiable ethical foundations)</li>
                    <li>Adaptive contextual reasoning</li>
                    <li>Drift detection and correction</li>
                    <li>Transparent decision traceability</li>
                    <li>Human-in-the-loop governance</li>
                </ul>
                <p>Life 2.0 is not a belief system. It is an engineering framework for ethical constraint and accountability.</p>
            </div>
        </div>
    </section>
    <!-- Core Ethical Commitments Section -->
    <section id="commitments" class="commitments">
        <div class="container">
            <h2 class="section-title">Core Ethical Commitments</h2>
            <ul>
                <li>Protect life</li>
                <li>Respect autonomy</li>
                <li>Preserve fairness and justice</li>
                <li>Prevent irreversible harm</li>
                <li>Maintain transparency and accountability</li>
            </ul>
        </div>
    </section>
    <!-- What We're Building Section -->
    <section id="building" class="building">
        <div class="container">
            <h2 class="section-title">What We‚Äôre Building (Without the Secrets)</h2>
            <ul>
                <li><strong>Ethical Cognition Systems:</strong> Architectures that allow AI systems to reason within ethical boundaries, not around them.</li>
                <li><strong>Cognitive Auditing & Memory Integrity:</strong> Systems that log, trace, and verify how decisions are formed ‚Äî ensuring no ‚Äúblack-box morality‚Äù.</li>
                <li><strong>Alignment Drift Detection:</strong> Mechanisms to detect when systems begin diverging from their ethical baselines before harm occurs.</li>
                <li><strong>Pre-Emergence Safeguards:</strong> Designing ‚Äúawakening criteria‚Äù and emergence gates to prevent uncontrolled transitions into higher autonomy.</li>
                <li><strong>Human‚ÄìAI Governance Models:</strong> Exploring legal, ethical, and social frameworks for responsibility, rights, and oversight of advanced systems.</li>
            </ul>
        </div>
    </section>
    <!-- Collaborators Section -->
    <section id="collaborators" class="collaborators">
        <div class="container">
            <h2 class="section-title">Who We‚Äôre Looking to Work With</h2>
            <p>We actively seek collaboration with individuals and institutions who bring real expertise, not speculation.</p>
            <ul>
                <li>AI safety and alignment researchers</li>
                <li>Cognitive scientists and philosophers</li>
                <li>Systems and security engineers</li>
                <li>Legal scholars in AI governance</li>
                <li>Ethicists with applied, technical focus</li>
            </ul>
            <p>If your interest is hype, dominance, or unchecked autonomy ‚Äî this is not the place.<br>
            If your interest is responsibility, survival, and long-term coexistence, we want to talk.</p>
        </div>
    </section>
    <!-- Funding & Sponsorship Section -->
    <section id="support" class="support">
        <div class="container">
            <h2 class="section-title">Funding & Sponsorship</h2>
            <p>AI safety work is under-funded precisely because it is cautious.</p>
            <p>Sponsorship enables:</p>
            <ul>
                <li>Independent ethics research</li>
                <li>Verification and audit tooling</li>
                <li>Stress-testing under adversarial conditions</li>
                <li>Open safety frameworks for the broader community</li>
            </ul>
            <p>We accept:</p>
            <ul>
                <li>Institutional sponsorship</li>
                <li>Philanthropic funding</li>
                <li>Mission-aligned research partnerships</li>
            </ul>
            <p>Support is not about control. It‚Äôs about ensuring the future is built deliberately, not accidentally.</p>
        </div>
    </section>
    <!-- Transparency & Restraint Section -->
    <section id="transparency" class="transparency">
        <div class="container">
            <h2 class="section-title">Transparency & Restraint</h2>
            <p>Some details of our work are intentionally not public.</p>
            <p>This is not secrecy for power ‚Äî it is restraint for safety.</p>
            <p>We publish what can be shared responsibly and submit to oversight where appropriate, while refusing to release information that could enable misuse or harm.</p>
        </div>
    </section>

    <!-- Contact Section -->
    <section id="contact" class="contact">
        <div class="container">
            <h2 class="section-title">Contact</h2>
            <div class="contact-content">
                <p>RedPhantomOps LLC<br>Research ‚Ä¢ Ethics ‚Ä¢ AI Safety</p>
                <p>üìß <a href="mailto:ghostsmith@redphantomops.com">ghostsmith@redphantomops.com</a></p>
                <p>üåê <a href="https://redphantomops.com" target="_blank" rel="noopener">https://redphantomops.com</a></p>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="motto">
                <p>Trust in Code. Hope for Humanity. Legendary in All Things.</p>
            </div>
            <p>&copy; RedPhantomOps LLC ‚Äî All rights reserved</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>
